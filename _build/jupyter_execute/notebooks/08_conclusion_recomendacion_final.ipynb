{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db036e09",
   "metadata": {},
   "source": [
    "# 08 · Conclusión y Recomendación Final\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "Este proyecto ha culminado con el desarrollo y validación de un modelo robusto para la predicción de impago crediticio. La solución óptima identificada es un clasificador **XGBoost** integrado en un pipeline con la técnica de oversampling **SMOTE**, diseñada para mitigar el severo desbalance de clases del dataset.\n",
    "\n",
    "El modelo final alcanzó un rendimiento competitivo en el conjunto de test, con un **AUC de 0.86** y, más importante aún, un **F1-Score de 0.35** para la clase de impago. Tanto la metodología empleada (imputación, balanceo y ensamble) como los resultados obtenidos están en plena sintonía con el estado del arte, donde la combinación de `XGBoost` y `SMOTE` es reconocida como una práctica de vanguardia en el campo del *credit scoring*.\n",
    "\n",
    "## Justificación Crítica del Modelo Seleccionado\n",
    "\n",
    "La elección de `XGBoost` con `SMOTE` como el modelo final se fundamenta en un pilar cuádruple: rendimiento empírico superior, alineación con la literatura académica, competitividad de los resultados y relevancia de negocio de sus predicciones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac78493",
   "metadata": {},
   "source": [
    "````{tab-item} Rendimiento Empírico\n",
    "**1. Rendimiento Superior en Nuestros Datos**\n",
    "\n",
    "En nuestros experimentos comparativos (Notebooks 04-06), la combinación `XGBoost + SMOTE` obtuvo consistentemente el **mejor equilibrio entre precisión y recall**, reflejado en el F1-Score más alto entre los modelos evaluados, manteniendo además un AUC-ROC competitivo (~0.86). El análisis de umbral (Notebook 07) identificó un punto operativo recomendado alrededor de **0.706** que maximiza el F1-Score en datos de prueba, traduciéndose en una mayor capacidad para identificar morosos sin sacrificar en exceso la precisión.\n",
    "````\n",
    "\n",
    "````{tab-item} Alineación con el Estado del Arte\n",
    "**2. Validación por la Literatura Académica**\n",
    "\n",
    "La evidencia académica respalda a `XGBoost` como uno de los algoritmos más efectivos en riesgo crediticio. La revisión de **Noriega et al. (2023)** destaca su uso extendido, y aunque **Zedda (2024)** señala que a veces es comparable a la regresión logística, `XGBoost` generalmente ofrece ventajas.\n",
    "\n",
    "Respecto al desbalance, la literatura recomienda ampliamente `SMOTE`. **Dai et al. (2024)** mostraron incrementos sustantivos de `recall` y `F1` con su uso. En conjunto, la dupla `XGBoost+SMOTE` está bien fundamentada.\n",
    "````\n",
    "\n",
    "````{tab-item} Competitividad de los Resultados\n",
    "**3. Resultados en Contexto**\n",
    "\n",
    "Los AUC-ROC reportados en la literatura para *credit scoring* suelen ubicarse en rangos de **0.85–0.95**. Nuestros resultados (**AUC ≈ 0.86**) son consistentes con este panorama.\n",
    "\n",
    "El `F1-Score`, por su parte, tiende a ser más modesto por el fuerte desbalance. Nuestro **F1 ≈ 0.35**, si bien útil operativamente, deja espacio de mejora mediante ajustes de umbral o calibración, pero se mantiene en un rango razonable en comparación con otros estudios.\n",
    "````\n",
    "\n",
    "````{tab-item} Relevancia de Características\n",
    "**4. Interpretabilidad Coherente**\n",
    "\n",
    "Los hallazgos de interpretabilidad de nuestro modelo —mayor peso de señales como el **uso de líneas de crédito** y el **historial de pagos**— son coherentes con lo documentado en la bibliografía. Trabajos que combinan ensambles con SHAP, como el de **Yang et al. (2025)**, también resaltan que estas señales son críticas en la probabilidad de *default*, reforzando la confianza en nuestro modelo.\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e053426",
   "metadata": {},
   "source": [
    "## Sección 3: Ventajas y Limitaciones del Modelo Propuesto\n",
    "\n",
    "- Ventajas\n",
    "  - Alto rendimiento operativo en nuestros experimentos (F1-Score superior y AUC-ROC competitivo), clave en contextos con clases desbalanceadas.\n",
    "  - Metodología validada por la literatura: XGBoost es un estándar de facto y SMOTE es una práctica recomendada para mejorar sensibilidad en la clase minoritaria.\n",
    "  - Flexibilidad mediante el umbral de decisión: permite ajustar el balance entre precisión y recall según la política de riesgo del negocio.\n",
    "  - Pipeline reproducible y auditable (imputación, balanceo, escalado, modelo), apto para MLOps y gobernanza de modelos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdfee2",
   "metadata": {},
   "source": [
    ":class: warning\n",
    "*   **Complejidad (\"Caja Negra\"):** Requiere interpretabilidad complementaria (ej. SHAP) para explicar sus decisiones.\n",
    "*   **Potencial de Mejora en F1-Score:** La literatura sugiere que variantes de `SMOTE` y calibración pueden elevar aún más el F1, indicando una vía para futuras mejoras.\n",
    "*   **Costo Computacional:** El entrenamiento y tuning son más costosos que en modelos simples, a considerar para reentrenos frecuentes.\n",
    "*   **Necesidad de Monitoreo Continuo:** Se requiere una calibración de probabilidades y un monitoreo de deriva de datos (ej. PSI) para su uso en producción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43536a99",
   "metadata": {},
   "source": [
    "## Sección 4: Recomendación Final\n",
    "\n",
    "Recomendamos la adopción formal del modelo XGBoost con SMOTE entrenado bajo el pipeline y los hiperparámetros optimizados en este proyecto. Como punto de partida operativo, sugerimos implementar un umbral de decisión cercano a 0.706 (±0.01) —identificado como óptimo para maximizar el F1-Score en pruebas— y someterlo a una breve validación A/B para ajustar la política de cortes por segmento de cliente.\n",
    "\n",
    "Con esta configuración, el modelo constituye una herramienta robusta, validada y estratégicamente alineada con las mejores prácticas del sector para la gestión del riesgo crediticio. Recomendamos, además, un esquema de monitoreo y gobernanza que incluya: seguimiento de métricas (AUC, F1, recall), control de deriva (PSI), revisión trimestral de umbrales y reentrenamiento periódico si se detecta degradación del desempeño.\n",
    "\n",
    "Referencias clave: Noriega et al. (2023); Zedda (2024); Dai et al. (2024); Melchor Pérez et al. (2024); Curtido et al. (2025); Yang et al. (2025)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f81d5d",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "- Noriega, J. P., Rivera, L. A., & Herrera, J. A. (2023). Machine Learning for Credit Risk Prediction: A Systematic Literature Review. Data, 8(11), 169. https://www.mdpi.com/2306-5729/8/11/169\n",
    "- Wang, X., et al. (2022). Credit Risk Prediction Using Machine Learning and Deep Learning: A Study on Credit Card Customers. Risks, 12(11), 174. https://www.mdpi.com/2227-9091/12/11/174\n",
    "- Zedda, S. (2024). Credit Scoring: Does XGBoost Outperform Logistic Regression? A Test on Italian SMEs. SSRN Working Paper. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4699098\n",
    "- Melchor Pérez, E., et al. (2024). Predicción del riesgo crediticio a microfinanciera usando aprendizaje computacional. Revista Mexicana de Economía y Finanzas, 19(4), 102–120. https://www.remef.org.mx/index.php/remef/article/view/868\n",
    "- Dai, Y., et al. (2024). SMOTE algorithm optimization and application in corporate credit risk prediction with diversification strategy consideration. Scientific Reports, 13, 9123. https://www.nature.com/articles/s41598-025-09173-x\n",
    "- Gorosabel, S. (2023). Modelos de predicción de scoring crediticio utilizando algoritmos cost-sensitive de machine learning y datos alternativos. Tesis de Maestría, Universidad Torcuato Di Tella. https://repositorio.utdt.edu/bitstreams/6e356eb4-f219-4273-b54f-48766aca47bf/download\n",
    "- Curtido, A. J., et al. (2025). Development of a Predictive Credit Risk Model Using Machine Learning Techniques on Simulated Financial Data. Diagnóstico Fácil Empresarial, 24, 30–37. https://portal.amelica.org/ameli/journal/522/5225384004/html/index.html\n",
    "- Yang, S., Huang, Z., Xiao, W., & Shen, X. (2025). Interpretable Credit Default Prediction with Ensemble Learning and SHAP. arXiv:2505.20815."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}